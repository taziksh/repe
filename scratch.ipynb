{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2ca6a0-c776-4639-9a73-b2374eb2ad35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6c1eeae86043c885379130e0cf0336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.environ['HF_TOKEN']\n",
    "\n",
    "torch.set_default_dtype(torch.float16)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token=token).to(device)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token=token).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99ea38fa-bed3-42a1-999e-723f111b185a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle = 31//2\n",
    "middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "489591c8-1ca0-470d-b4c7-0daf08dca826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.layers.15',\n",
       " 'model.layers.15.self_attn',\n",
       " 'model.layers.15.self_attn.q_proj',\n",
       " 'model.layers.15.self_attn.k_proj',\n",
       " 'model.layers.15.self_attn.v_proj',\n",
       " 'model.layers.15.self_attn.o_proj',\n",
       " 'model.layers.15.self_attn.rotary_emb',\n",
       " 'model.layers.15.mlp',\n",
       " 'model.layers.15.mlp.gate_proj',\n",
       " 'model.layers.15.mlp.up_proj',\n",
       " 'model.layers.15.mlp.down_proj',\n",
       " 'model.layers.15.mlp.act_fn',\n",
       " 'model.layers.15.input_layernorm',\n",
       " 'model.layers.15.post_attention_layernorm']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_layers = [module for module in dict(model.named_modules()).keys() if f\"layers.{middle}\" in module]\n",
    "middle_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c0c15-bc2b-41c0-94cb-9c87353d6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc45c1-e88e-4e0f-ba38-bbd3abb1b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 1\n",
    "for epoch in E:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
